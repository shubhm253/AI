{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhm253/AI/blob/master/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bffyLVb8C8f7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "b0078f56-4260-4bbe-a91c-e9a2d86b79e7"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjNevE32C_Ub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "c4a79621-1bb2-42af-efe8-20ed8ae2f296"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"MNIST_data/\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-7d08ec3dfcb7>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEEV5RtXELxT",
        "colab_type": "text"
      },
      "source": [
        "The MNIST dataset consists:\n",
        "mnist.train: 55000 training images\n",
        "mnist.validation: 5000 validation images\n",
        "mnist.test: 10000 test images\n",
        "Each image is 28 pixels (rows) by 28 pixels (cols). We treat each image as a sequence of data, that is, the first row is the first step; second row is the second step and so on. Therefore, n_steps = number of rows and n_inputs = number of columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzmijxWTDPUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0A0TNb7sES49",
        "colab_type": "text"
      },
      "source": [
        "The mnist dataset from TensorFlow assumes that you are using one-hot encoding, however, we are not going to do that. Therefore, we need to reshape the dataset from [num_data, 28*28] to [num_data, n_steps, n_inputs]. Since there are many outputs from the RNN, we only care about the last one. As a result, “state” in the code is considered as our output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOniDNntDFDy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "a3f7ce68-91cc-4fba-c5b7-e898ffe16f30"
      },
      "source": [
        "# hyperparameters\n",
        "n_neurons = 128\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "n_epochs = 10\n",
        "# parameters\n",
        "n_steps = 28 # 28 rows\n",
        "n_inputs = 28 # 28 cols\n",
        "n_outputs = 10 # 10 classes\n",
        "# build a rnn model\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
        "output, state = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
        "logits = tf.layers.dense(state, n_outputs)\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(cross_entropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "prediction = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-43ecd88b34e7>:12: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-5-43ecd88b34e7>:13: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From <ipython-input-5-43ecd88b34e7>:14: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp_FJSBWF-_2",
        "colab_type": "text"
      },
      "source": [
        "Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Snn9X_TEYKN",
        "colab_type": "text"
      },
      "source": [
        "Reshape the test dataset to [num_test, n_steps, n_inputs]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2JcRMaTDI5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input data\n",
        "#from tensorflow.examples.tutorials.mnist import input_data\n",
        "#mnist = input_data.read_data_sets(“MNIST_data/”)\n",
        "X_test = mnist.test.images # X_test shape: [num_test, 28*28]\n",
        "X_test = X_test.reshape([-1, n_steps, n_inputs])\n",
        "y_test = mnist.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DJau-cODWpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5f297ce5-2902-45d7-bb90-1f7a964b20ea"
      },
      "source": [
        "# initialize the variables\n",
        "init = tf.global_variables_initializer()\n",
        "# train the model\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    n_batches = mnist.train.num_examples // batch_size\n",
        "    for epoch in range(n_epochs):\n",
        "        for batch in range(n_batches):\n",
        "            X_train, y_train = mnist.train.next_batch(batch_size)\n",
        "            X_train = X_train.reshape([-1, n_steps, n_inputs])\n",
        "            sess.run(optimizer, feed_dict={X: X_train, y: y_train})\n",
        "        loss_train, acc_train = sess.run(\n",
        "            [loss, accuracy], feed_dict={X: X_train, y: y_train})\n",
        "        print('Epoch: {}, Train Loss: {:.3f}, Train Acc: {:.3f}'.format(\n",
        "            epoch + 1, loss_train, acc_train))\n",
        "    loss_test, acc_test = sess.run(\n",
        "        [loss, accuracy], feed_dict={X: X_test, y: y_test})\n",
        "    print('Test Loss: {:.3f}, Test Acc: {:.3f}'.format(loss_test, acc_test))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train Loss: 0.264, Train Acc: 0.898\n",
            "Epoch: 2, Train Loss: 0.239, Train Acc: 0.930\n",
            "Epoch: 3, Train Loss: 0.182, Train Acc: 0.938\n",
            "Epoch: 4, Train Loss: 0.062, Train Acc: 0.977\n",
            "Epoch: 5, Train Loss: 0.061, Train Acc: 0.992\n",
            "Epoch: 6, Train Loss: 0.089, Train Acc: 0.969\n",
            "Epoch: 7, Train Loss: 0.070, Train Acc: 0.984\n",
            "Epoch: 8, Train Loss: 0.074, Train Acc: 0.969\n",
            "Epoch: 9, Train Loss: 0.033, Train Acc: 0.992\n",
            "Epoch: 10, Train Loss: 0.043, Train Acc: 0.992\n",
            "Test Loss: 0.098, Test Acc: 0.970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW_lkRlFDoxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}